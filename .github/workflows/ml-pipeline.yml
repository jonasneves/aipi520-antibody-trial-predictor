name: ML Pipeline
run-name: "${{ github.event_name == 'workflow_dispatch' && format('ML Pipeline - {0} studies', github.event.inputs.max_studies) || format('ML Pipeline - {0}', github.ref_name) }}"

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'models/**'
      - 'scripts/**'
      - 'src/**'
      - 'requirements.txt'
      - 'run_pipeline.py'
      - '.github/workflows/ml-pipeline.yml'
  workflow_dispatch:
    inputs:
      max_studies:
        description: 'Maximum antibody trials to collect'
        required: false
        default: '50000'
        type: string

permissions:
  contents: write
  id-token: write

env:
  MAX_STUDIES: ${{ github.event.inputs.max_studies || '50000' }}

jobs:
  # Stage 1: Data Collection & Feature Engineering
  prepare:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Create data directory
        run: mkdir -p data

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1

      - name: Check for cached features in S3
        id: s3-cache
        run: |
          S3_KEY="features/clinical_trials_features_${{ env.MAX_STUDIES }}.csv"
          if aws s3 ls "s3://aipi520-antibody-trial-predictor/$S3_KEY" 2>/dev/null; then
            echo "cache-hit=true" >> $GITHUB_OUTPUT
            echo "s3-key=$S3_KEY" >> $GITHUB_OUTPUT
          else
            echo "cache-hit=false" >> $GITHUB_OUTPUT
            echo "s3-key=$S3_KEY" >> $GITHUB_OUTPUT
          fi

      - name: Download cached features from S3
        if: steps.s3-cache.outputs.cache-hit == 'true'
        run: |
          aws s3 cp "s3://aipi520-antibody-trial-predictor/${{ steps.s3-cache.outputs.s3-key }}" data/clinical_trials_features.csv
          echo "Downloaded cached features from S3"

      - name: Collect data and engineer features
        if: steps.s3-cache.outputs.cache-hit != 'true'
        run: python run_pipeline.py --steps collect label features --max-studies ${{ env.MAX_STUDIES }}

      - name: Upload features to S3
        if: steps.s3-cache.outputs.cache-hit != 'true'
        run: |
          aws s3 cp data/clinical_trials_features.csv "s3://aipi520-antibody-trial-predictor/${{ steps.s3-cache.outputs.s3-key }}"
          echo "Uploaded features to S3"

      - name: Create data preparation summary
        run: |
          if [ "${{ steps.s3-cache.outputs.cache-hit }}" == "true" ]; then
            echo "# Data Preparation Complete (Cached from S3)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**S3 cache hit!** Downloaded cached feature data from S3" >> $GITHUB_STEP_SUMMARY
            echo "Skipped data collection, labeling, and feature engineering" >> $GITHUB_STEP_SUMMARY
          else
            echo "# Data Preparation Complete" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Data Source:** ClinicalTrials.gov API" >> $GITHUB_STEP_SUMMARY
            echo "**Uploaded to:** S3 for future use" >> $GITHUB_STEP_SUMMARY
          fi
          echo "**Max Studies:** ${{ env.MAX_STUDIES }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Generated Files" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          ls -lh data/clinical_trials_features.csv >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          SAMPLES=$(tail -n +2 data/clinical_trials_features.csv | wc -l)
          FEATURES=$(head -1 data/clinical_trials_features.csv | tr ',' '\n' | wc -l)

          echo "**Samples:** $SAMPLES trials" >> $GITHUB_STEP_SUMMARY
          echo "**Features:** $FEATURES columns" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "<details>" >> $GITHUB_STEP_SUMMARY
          echo "<summary>View Sample Data (first 3 rows)</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```csv' >> $GITHUB_STEP_SUMMARY
          head -4 data/clinical_trials_features.csv >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "<details>" >> $GITHUB_STEP_SUMMARY
          echo "<summary>View All Features ($FEATURES total)</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          head -1 data/clinical_trials_features.csv | tr ',' '\n' | nl >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY

      - name: Upload feature data
        uses: actions/upload-artifact@v4
        with:
          name: feature-data
          path: data
          retention-days: 1

  # Stage 2: Train Models in Parallel (Matrix Strategy)
  train:
    needs: prepare
    runs-on: ubuntu-latest
    timeout-minutes: 20

    strategy:
      fail-fast: false
      matrix:
        model:
          - name: 'Logistic Regression'
            code: 'lr'
          - name: 'Decision Tree'
            code: 'dt'
          - name: 'Random Forest'
            code: 'rf'
          - name: 'Gradient Boosting'
            code: 'gb'
          - name: 'XGBoost'
            code: 'xgb'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Download feature data
        uses: actions/download-artifact@v4
        with:
          name: feature-data
          path: data

      - name: Train ${{ matrix.model.name }}
        run: |
          python scripts/train_single_model.py \
            ${{ matrix.model.code }} \
            data/clinical_trials_features.csv \
            models/

      - name: Create model training summary
        run: |
          echo "# ${{ matrix.model.name }} Training Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          cat models/results_${{ matrix.model.code }}.json >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Upload model and results
        uses: actions/upload-artifact@v4
        with:
          name: model-${{ matrix.model.code }}
          path: |
            models/${{ matrix.model.code }}_model.pkl
            models/results_${{ matrix.model.code }}.json
          retention-days: 30

  # Stage 3: Aggregate Results and Compare
  aggregate:
    needs: train
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: pip install pandas plotly

      - name: Download all model results
        uses: actions/download-artifact@v4
        with:
          pattern: model-*
          merge-multiple: true
          path: models

      - name: Generate report (CSV + HTML)
        run: |
          python scripts/generate_report.py models reports/model_comparison.csv docs/index.html \
            --timestamp "$(date -u +'%Y-%m-%d %H:%M:%S UTC')" \
            --workflow-url "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            --repo "${{ github.repository }}"

      - name: Deploy dashboard
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs
          publish_branch: gh-pages
          commit_message: "Dashboard: ${{ env.MAX_STUDIES }} trials"

      - name: Commit results
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add models/*.pkl reports/model_comparison.csv docs/index.html || true
          if ! git diff --staged --quiet; then
            git commit -m "Pipeline results: ${{ env.MAX_STUDIES }} trials - $(date -u +%Y-%m-%d)"
            git push
          fi

      - name: Create pipeline summary
        run: |
          echo "# ML Pipeline Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Max Studies:** ${{ env.MAX_STUDIES }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Data Source:** ClinicalTrials.gov API" >> $GITHUB_STEP_SUMMARY
          echo "- **Models Trained:** 5 (in parallel)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f reports/model_comparison.csv ]; then
            # Extract best model info
            BEST_MODEL=$(tail -n +2 reports/model_comparison.csv | head -n 1 | cut -d',' -f1)
            BEST_AUC=$(tail -n +2 reports/model_comparison.csv | head -n 1 | cut -d',' -f6)

            echo "## Best Model" >> $GITHUB_STEP_SUMMARY
            echo "**${BEST_MODEL}** with ROC AUC: **${BEST_AUC}**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            echo "## Model Comparison" >> $GITHUB_STEP_SUMMARY
            echo '```csv' >> $GITHUB_STEP_SUMMARY
            cat reports/model_comparison.csv >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            echo "## Live Dashboard" >> $GITHUB_STEP_SUMMARY
            echo "View the interactive results at:" >> $GITHUB_STEP_SUMMARY
            echo "**https://jonasneves.github.io/aipi520-project2/**" >> $GITHUB_STEP_SUMMARY
          else
            echo "WARNING: Model comparison report not found" >> $GITHUB_STEP_SUMMARY
          fi
